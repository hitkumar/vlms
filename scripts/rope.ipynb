{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from dataclasses import dataclass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "labels = torch.arange(6)\n",
        "labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "labels = labels.roll(-1)\n",
        "labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "labels[-1] = -100\n",
        "labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class VLMConfig:\n",
        "    vit_hidden_dim: int = 768\n",
        "    vit_inter_dim: int = 4 * vit_hidden_dim\n",
        "    vit_patch_size: int = 16\n",
        "    vit_img_size: int = 512\n",
        "    vit_n_heads: int = 12\n",
        "    vit_dropout: float = 0.0\n",
        "    vit_n_blocks: int = 12\n",
        "    vit_ln_eps: float = 1e-6\n",
        "    vit_cls_flag: bool = False\n",
        "    vit_model_type: str = (\n",
        "        \"google/siglip-base-patch16-512\"  #'google/siglip-base-patch16-224'\n",
        "    )\n",
        "\n",
        "    lm_hidden_dim: int = 576\n",
        "    lm_inter_dim: int = 1536\n",
        "    lm_rms_eps: float = 1e-5\n",
        "    lm_re_base: int = 100000\n",
        "    lm_max_position_embeddings: int = 8192\n",
        "    lm_vocab_size: int = 49280\n",
        "    lm_n_heads: int = 9\n",
        "    lm_n_kv_heads: int = 3\n",
        "    lm_dropout: float = 0.0\n",
        "    lm_n_blocks: int = 30\n",
        "    lm_attn_scaling: float = 1.0\n",
        "    lm_max_length: int = (\n",
        "        256 - 64\n",
        "    )  # Deduct the image token length to achieve a 'nice number'\n",
        "    lm_use_tokens: bool = (\n",
        "        False  # Decide if the LM expects tokens or embeddings as input (if using as a backbone for the VLM, set to False)\n",
        "    )\n",
        "    lm_tie_weights: bool = (\n",
        "        False  # Decide if you want to tie the LM Head weight to the token embeding weights\n",
        "    )\n",
        "    lm_model_type: str = \"HuggingFaceTB/SmolLM2-135M\"\n",
        "    lm_tokenizer: str = \"HuggingFaceTB/cosmo2-tokenizer\"\n",
        "    lm_eos_token_id: int = 0\n",
        "\n",
        "    mp_pixel_shuffle_factor: int = 4\n",
        "\n",
        "    vlm_load_backbone_weights: bool = True\n",
        "    vlm_checkpoint_path: str = \"vlm_model_0502_smolvlm.pth\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cfg = VLMConfig()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cfg.lm_hidden_dim, cfg.lm_n_heads"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dim = cfg.lm_hidden_dim // cfg.lm_n_heads; dim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "base = cfg.lm_re_base; base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "max_seq_len = cfg.lm_max_position_embeddings; max_seq_len"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "inv_freq = 1.0 / (base ** (torch.arange(0, dim, 2).float() / dim))\n",
        "inv_freq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "original_max_seq_len = cfg.lm_max_position_embeddings\n",
        "original_max_seq_len"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "position_ids = torch.arange(4).unsqueeze(0).expand(1, -1)\n",
        "position_ids.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "batch_size, seq_len = position_ids.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "flat_position_ids = position_ids.reshape(-1).float()\n",
        "flat_position_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "inv_freq.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "freqs = flat_position_ids.unsqueeze(-1) * inv_freq.unsqueeze(0)\n",
        "freqs.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "freqs = freqs.reshape(1, 4, -1)\n",
        "freqs.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "freqs[0, 1, 0], freqs[0, 1, 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "emb = torch.cat([freqs, freqs], dim=-1)\n",
        "emb.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "emb[0, 1, 0], emb[0, 1, 1], emb[0, 1, 2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dim = 32\n",
        "emb[0, 1, 0 + dim], emb[0, 1, 1 + dim], emb[0, 1, 2 + dim]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cos = torch.cos(emb)\n",
        "sin = torch.sin(emb)\n",
        "cos.shape, sin.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def rotate_half(x):\n",
        "    x1, x2 = x.chunk(2, dim=-1)\n",
        "    return torch.cat((-x2, x1), dim=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cos = cos.unsqueeze(1)\n",
        "sin = sin.unsqueeze(1)\n",
        "cos.shape, sin.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "q = torch.arange(4 * 64).view(1, 1, 4, 64)\n",
        "q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "q_rotated = rotate_half(q)\n",
        "q_rotated"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "a = torch.arange(4 * 64).reshape(4, 64)\n",
        "a.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "b = a.reshape(-1)\n",
        "b.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "a = torch.arange(12).reshape(3, 4)\n",
        "a.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "b = a.repeat_interleave(2, dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "fileHeader": "",
    "fileUid": "fc2ce836-ba78-44b7-9db9-5f9cab64ca9e",
    "isAdHoc": false,
    "kernelspec": {
      "display_name": "deep_rl (local)",
      "language": "python",
      "name": "deep_rl_local"
    }
  }
}
