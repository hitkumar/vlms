{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import timeit\n",
        "from typing import Iterable\n",
        "from jaxtyping import Float\n",
        "\n",
        "from einops import rearrange, einsum, reduce"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# https://www.nvidia.com/content/dam/en-zz/Solutions/Data-Center/a100/pdf/nvidia-a100-datasheet-us-nvidia-1758950-r4-web.pdf\n",
        "a100_flop_per_sec = 312e12  # 312 TFLOP/s\n",
        "\n",
        "# https://resources.nvidia.com/en-us-tensor-core/nvidia-tensor-core-gpu-datasheet\n",
        "h100_flop_per_sec = 1979e12 / 2  # 1979 TFLOP/s with sparsity (BF16 tensor core)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "total_flops = 6 * 70e9 * 15e12  # @inspect total_flops\n",
        "assert h100_flop_per_sec == 1979e12 / 2\n",
        "mfu = 0.5\n",
        "flops_per_day = h100_flop_per_sec * mfu * 1024 * 60 * 60 * 24  # @inspect flops_per_day\n",
        "days = total_flops / flops_per_day  # @inspect days\n",
        "print(f\"days: {days}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "h100_bytes = 80e9\n",
        "bytes_per_parameter = 4 + 4 + (4 + 4)\n",
        "num_params = h100_bytes / bytes_per_parameter\n",
        "print(f\"num_params: {num_params}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_memory_usage(x: torch.tensor):\n",
        "    return x.numel() * x.element_size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x = torch.zeros(4, 8)\n",
        "x.dtype, x.numel(), get_memory_usage(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "a = torch.empty(12288 * 4, 12288)\n",
        "a.element_size(), a.numel()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "get_memory_usage(a) / (1e9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x = torch.zeros(4, 8, dtype=torch.float16)\n",
        "x.element_size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x = torch.tensor([1e-8], dtype=torch.float16)\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x = torch.tensor([1e-8], dtype=torch.bfloat16); x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.finfo(torch.bfloat16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x.device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "num_gpus = torch.cuda.device_count(); num_gpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for i in range(num_gpus):\n",
        "    properties = torch.cuda.get_device_name(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "properties"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "memory_allocated = torch.cuda.memory_allocated(); memory_allocated"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y = x.to('cuda:0')\n",
        "# y.device\n",
        "# assert y.device == torch.device(\"cuda\", 0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "get_memory_usage(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "new_memory_usage = torch.cuda.memory_allocated()\n",
        "memory_used = new_memory_usage - memory_allocated; memory_used"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "new_memory_usage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.cuda.memory_allocated()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "memory_allocated = torch.cuda.memory_allocated()  # @inspect memory_allocated\n",
        "x = torch.zeros(32, 32)\n",
        "y = x.to(\"cuda:0\")\n",
        "assert y.device == torch.device(\"cuda\", 0)\n",
        "\n",
        "z = torch.zeros(32, 32, device=\"cuda:0\")\n",
        "\n",
        "new_memory_allocated = torch.cuda.memory_allocated()  # @inspect new_memory_allocated\n",
        "memory_used = new_memory_allocated - memory_allocated  # @inspect memory_used\n",
        "# assert memory_used == 2 * (32 * 32 * 4)  # 2 32x32 matrices of 4-byte floats\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "memory_used"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x = torch.ones(4, 8, 16, 32)\n",
        "w = torch.ones(32, 2)\n",
        "y = x@w\n",
        "y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# MFU is actual flops / promised flops"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x = torch.tensor([1., 2., 3.])\n",
        "w = torch.tensor([1., 1., 1.], requires_grad=True)\n",
        "pred_y = x @ w\n",
        "pred_y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "input_dim = 16384\n",
        "output_dim = 32\n",
        "w = nn.Parameter(torch.randn(input_dim, output_dim))\n",
        "x = nn.Parameter(torch.randn(input_dim))\n",
        "w.shape, x.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "output = x @ w\n",
        "output.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "output[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "w = nn.Parameter(torch.randn(input_dim, output_dim) / np.sqrt(input_dim))\n",
        "output = x @ w  # @inspect output\n",
        "output[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "w = torch.tensor([1., 1., 1.], requires_grad=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class SGD(torch.optim.Optimizer):\n",
        "    def __init__(self, params: Iterable[nn.Parameter], lr: float = 0.01):\n",
        "        super(SGD, self).__init__(params, dict(lr=lr))\n",
        "\n",
        "    def step(self):\n",
        "        for group in self.param_groups:\n",
        "            lr = group['lr']\n",
        "            for p in group['params']:\n",
        "                grad = p.grad.data\n",
        "                p.data -= lr * grad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sgd = SGD([w])\n",
        "sgd.param_groups"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "fileHeader": "",
    "fileUid": "370e5c70-cb2e-4360-9b76-33d2dbda53d5",
    "isAdHoc": false,
    "kernelspec": {
      "display_name": "deep_rl (local)",
      "language": "python",
      "name": "deep_rl_local"
    }
  }
}
